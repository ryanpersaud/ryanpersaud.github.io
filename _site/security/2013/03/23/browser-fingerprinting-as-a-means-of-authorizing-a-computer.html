<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Browser fingerprinting as a means of authorizing a computer | Ryan Persaud’s blog</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Browser fingerprinting as a means of authorizing a computer" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD HTML 4.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/REC-html40/loose.dtd&quot;&gt; &lt;/p&gt; I was looking into screen scraping the sites of some of the financial companies that I use, and the process was pretty similar to what I had done for other projects in the past (fantasy football stat tracker, WMATA train tracker, etc.).  One aspect that differed was the need to authenticate to the site before being able to scrape data.  For most of the sites, it was just a matter of POSTing my credentials to a particular URL.   However, one site presented difficulties because it would only allow logins from ‘authorized’ computers.  Though I did not break any laws in my examination of the site, I am not mentioning the company that owns the site because I don’t want to deal with overzealous lawyers.  For the remainder of this post, I will refer to the company as Vandelay Industries (VI).  The authorization process involved: a) Attempting to login. b) Getting a message that the current machine has not been authorized along with a link to send an authorization code to the phone number registered to the account. c) Keying in the authorization code. After completing those steps, the computer was now authorized and a user could login as normal.   Armed with a host of Firefox extensions (Firebug, Cookies Manager+ and Better Privacy), I was able to determine that once step c is completed, a Flash Cookie is stored on the computer to record that it has been authorized.  On subsequent visits to the site, the Flash Cookie will be provided to the site, and the user will be able to login.  I verified this by transplanting the flash cookie to a computer that I had not previously authorized and successfully logging in to the site.  This is all well and good, but I had no idea how to integrate a Flash Cookie into a screen scraping script.  After some pondering, I realized that the site could not rely on all machines having Flash, so I fired up a browser that did not have the Flash plugin installed and observed what happened during the authorization process.  My assumption was that ‘normal’ browser cookies would be used, and if the user happened to clear their cookies, then tough luck, they would have to reauthorize their browser.  However, I cleared all of the cookies for the site, and I was still able to login, so clearly cookies were not being used.  After some Googling and poking around, I realized that the site was using browser fingerprinting to authorize a machine (at least the browser). The basic idea of browser fingerprinting is that a site can collect freely available information about a user’s browser to create a unique profile of that browser.  My initial thought was that there would be a lot of browsers with identical fingerprints, but as you can see from this site that the EFF put together, it is possible to gather a set of information that uniquely identifies browsers, even with a decent sample size (nearly 3 million).  It appears that plug-ins are the most useful at providing unique information.  VI is also banking on the fact that even if multiple browsers have the same fingerprint, the chances that an attacker would have the same fingerprint as an victim are low. That said, fingerprinting has a clear disadvantage when compared to the Flash Cookie approach.  Any site that a user visits can obtain the browser fingerprint, while Flash Cookies ‘should’ only be provided to the site that created the cookie.  An attacker who manages to obtain a victim’s credentials through phishing would have no trouble obtaining a browser fingerprint as well.&lt;/body&gt;&lt;/html&gt;" />
<meta property="og:description" content="&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD HTML 4.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/REC-html40/loose.dtd&quot;&gt; &lt;/p&gt; I was looking into screen scraping the sites of some of the financial companies that I use, and the process was pretty similar to what I had done for other projects in the past (fantasy football stat tracker, WMATA train tracker, etc.).  One aspect that differed was the need to authenticate to the site before being able to scrape data.  For most of the sites, it was just a matter of POSTing my credentials to a particular URL.   However, one site presented difficulties because it would only allow logins from ‘authorized’ computers.  Though I did not break any laws in my examination of the site, I am not mentioning the company that owns the site because I don’t want to deal with overzealous lawyers.  For the remainder of this post, I will refer to the company as Vandelay Industries (VI).  The authorization process involved: a) Attempting to login. b) Getting a message that the current machine has not been authorized along with a link to send an authorization code to the phone number registered to the account. c) Keying in the authorization code. After completing those steps, the computer was now authorized and a user could login as normal.   Armed with a host of Firefox extensions (Firebug, Cookies Manager+ and Better Privacy), I was able to determine that once step c is completed, a Flash Cookie is stored on the computer to record that it has been authorized.  On subsequent visits to the site, the Flash Cookie will be provided to the site, and the user will be able to login.  I verified this by transplanting the flash cookie to a computer that I had not previously authorized and successfully logging in to the site.  This is all well and good, but I had no idea how to integrate a Flash Cookie into a screen scraping script.  After some pondering, I realized that the site could not rely on all machines having Flash, so I fired up a browser that did not have the Flash plugin installed and observed what happened during the authorization process.  My assumption was that ‘normal’ browser cookies would be used, and if the user happened to clear their cookies, then tough luck, they would have to reauthorize their browser.  However, I cleared all of the cookies for the site, and I was still able to login, so clearly cookies were not being used.  After some Googling and poking around, I realized that the site was using browser fingerprinting to authorize a machine (at least the browser). The basic idea of browser fingerprinting is that a site can collect freely available information about a user’s browser to create a unique profile of that browser.  My initial thought was that there would be a lot of browsers with identical fingerprints, but as you can see from this site that the EFF put together, it is possible to gather a set of information that uniquely identifies browsers, even with a decent sample size (nearly 3 million).  It appears that plug-ins are the most useful at providing unique information.  VI is also banking on the fact that even if multiple browsers have the same fingerprint, the chances that an attacker would have the same fingerprint as an victim are low. That said, fingerprinting has a clear disadvantage when compared to the Flash Cookie approach.  Any site that a user visits can obtain the browser fingerprint, while Flash Cookies ‘should’ only be provided to the site that created the cookie.  An attacker who manages to obtain a victim’s credentials through phishing would have no trouble obtaining a browser fingerprint as well.&lt;/body&gt;&lt;/html&gt;" />
<link rel="canonical" href="http://0.0.0.0:4000/security/2013/03/23/browser-fingerprinting-as-a-means-of-authorizing-a-computer.html" />
<meta property="og:url" content="http://0.0.0.0:4000/security/2013/03/23/browser-fingerprinting-as-a-means-of-authorizing-a-computer.html" />
<meta property="og:site_name" content="Ryan Persaud’s blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2013-03-23T20:25:09+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Browser fingerprinting as a means of authorizing a computer" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2013-03-23T20:25:09+00:00","datePublished":"2013-03-23T20:25:09+00:00","description":"&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD HTML 4.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/REC-html40/loose.dtd&quot;&gt; &lt;/p&gt; I was looking into screen scraping the sites of some of the financial companies that I use, and the process was pretty similar to what I had done for other projects in the past (fantasy football stat tracker, WMATA train tracker, etc.).  One aspect that differed was the need to authenticate to the site before being able to scrape data.  For most of the sites, it was just a matter of POSTing my credentials to a particular URL.   However, one site presented difficulties because it would only allow logins from ‘authorized’ computers.  Though I did not break any laws in my examination of the site, I am not mentioning the company that owns the site because I don’t want to deal with overzealous lawyers.  For the remainder of this post, I will refer to the company as Vandelay Industries (VI).  The authorization process involved: a) Attempting to login. b) Getting a message that the current machine has not been authorized along with a link to send an authorization code to the phone number registered to the account. c) Keying in the authorization code. After completing those steps, the computer was now authorized and a user could login as normal.   Armed with a host of Firefox extensions (Firebug, Cookies Manager+ and Better Privacy), I was able to determine that once step c is completed, a Flash Cookie is stored on the computer to record that it has been authorized.  On subsequent visits to the site, the Flash Cookie will be provided to the site, and the user will be able to login.  I verified this by transplanting the flash cookie to a computer that I had not previously authorized and successfully logging in to the site.  This is all well and good, but I had no idea how to integrate a Flash Cookie into a screen scraping script.  After some pondering, I realized that the site could not rely on all machines having Flash, so I fired up a browser that did not have the Flash plugin installed and observed what happened during the authorization process.  My assumption was that ‘normal’ browser cookies would be used, and if the user happened to clear their cookies, then tough luck, they would have to reauthorize their browser.  However, I cleared all of the cookies for the site, and I was still able to login, so clearly cookies were not being used.  After some Googling and poking around, I realized that the site was using browser fingerprinting to authorize a machine (at least the browser). The basic idea of browser fingerprinting is that a site can collect freely available information about a user’s browser to create a unique profile of that browser.  My initial thought was that there would be a lot of browsers with identical fingerprints, but as you can see from this site that the EFF put together, it is possible to gather a set of information that uniquely identifies browsers, even with a decent sample size (nearly 3 million).  It appears that plug-ins are the most useful at providing unique information.  VI is also banking on the fact that even if multiple browsers have the same fingerprint, the chances that an attacker would have the same fingerprint as an victim are low. That said, fingerprinting has a clear disadvantage when compared to the Flash Cookie approach.  Any site that a user visits can obtain the browser fingerprint, while Flash Cookies ‘should’ only be provided to the site that created the cookie.  An attacker who manages to obtain a victim’s credentials through phishing would have no trouble obtaining a browser fingerprint as well.&lt;/body&gt;&lt;/html&gt;","headline":"Browser fingerprinting as a means of authorizing a computer","mainEntityOfPage":{"@type":"WebPage","@id":"http://0.0.0.0:4000/security/2013/03/23/browser-fingerprinting-as-a-means-of-authorizing-a-computer.html"},"url":"http://0.0.0.0:4000/security/2013/03/23/browser-fingerprinting-as-a-means-of-authorizing-a-computer.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://0.0.0.0:4000/feed.xml" title="Ryan Persaud&apos;s blog" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Ryan Persaud&#39;s blog</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Browser fingerprinting as a means of authorizing a computer</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2013-03-23T20:25:09+00:00" itemprop="datePublished">Mar 23, 2013
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p><!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"><br />
<html><body></p>
<p id="internal-source-marker_0.4753409114356536" dir="ltr">I was looking into screen scraping the sites of some of the financial companies that I use, and the process was pretty similar to what I had done for other projects in the past (fantasy football stat tracker, WMATA train tracker, etc.).  One aspect that differed was the need to authenticate to the site before being able to scrape data.  For most of the sites, it was just a matter of POSTing my credentials to a particular URL.   However, one site presented difficulties because it would only allow logins from ‘authorized’ computers.  Though I did not break any laws in my examination of the site, I am not mentioning the company that owns the site because I don’t want to deal with overzealous lawyers.  For the remainder of this post, I will refer to the company as Vandelay Industries (VI).  The authorization process involved:</p>
<p dir="ltr">a) Attempting to login.</p>
<p dir="ltr">b) Getting a message that the current machine has not been authorized along with a link to send an authorization code to the phone number registered to the account.</p>
<p dir="ltr">c) Keying in the authorization code.</p>
<p dir="ltr">After completing those steps, the computer was now authorized and a user could login as normal.   Armed with a host of Firefox extensions (Firebug, Cookies Manager+ and Better Privacy), I was able to determine that once step c is completed, a Flash Cookie is stored on the computer to record that it has been authorized.  On subsequent visits to the site, the Flash Cookie will be provided to the site, and the user will be able to login.  I verified this by transplanting the flash cookie to a computer that I had not previously authorized and successfully logging in to the site.  This is all well and good, but I had no idea how to integrate a Flash Cookie into a screen scraping script.  After some pondering, I realized that the site could not rely on all machines having Flash, so I fired up a browser that did not have the Flash plugin installed and observed what happened during the authorization process.  My assumption was that ‘normal’ browser cookies would be used, and if the user happened to clear their cookies, then tough luck, they would have to reauthorize their browser.  However, I cleared all of the cookies for the site, and I was still able to login, so clearly cookies were not being used.  After some Googling and poking around, I realized that the site was using browser fingerprinting to authorize a machine (at least the browser).</p>
<p>The basic idea of browser fingerprinting is that a site can collect freely available information about a user’s browser to create a unique profile of that browser.  My initial thought was that there would be a lot of browsers with identical fingerprints, but as you can see from this <a href="https://panopticlick.eff.org/">site </a>that the EFF put together, it is possible to gather a set of information that uniquely identifies browsers, even with a decent sample size (nearly 3 million).  It appears that plug-ins are the most useful at providing unique information.  VI is also banking on the fact that even if multiple browsers have the same fingerprint, the chances that an attacker would have the same fingerprint as an victim are low. That said, fingerprinting has a clear disadvantage when compared to the Flash Cookie approach.  Any site that a user visits can obtain the browser fingerprint, while Flash Cookies ‘should’ only be provided to the site that created the cookie.  An attacker who manages to obtain a victim’s credentials through phishing would have no trouble obtaining a browser fingerprint as well.</body></html></p>

  </div><a class="u-url" href="/security/2013/03/23/browser-fingerprinting-as-a-means-of-authorizing-a-computer.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Ryan Persaud&#39;s blog</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Ryan Persaud&#39;s blog</li><li><a class="u-email" href="mailto:ryan.persaud At Google's Email Service">ryan.persaud At Google's Email Service</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/ryanpersaud"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">ryanpersaud</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>This is apparently where all of my musings have ended up.</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
